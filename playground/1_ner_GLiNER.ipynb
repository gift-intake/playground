{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example uses the default GLiNER model to perform named entity recognition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, field_validator\n",
    "from typing import List\n",
    "\n",
    "class Entity(BaseModel):\n",
    "    entity: str\n",
    "    types: str\n",
    "    \n",
    "    @field_validator('entity')\n",
    "    @classmethod\n",
    "    def clean_entity(cls, v):\n",
    "        # Take only the text before the comma if there is one\n",
    "        if isinstance(v, str) and \",\" in v:\n",
    "            return v.split(\",\")[0].strip()\n",
    "        return v\n",
    "\n",
    "class Result(BaseModel):\n",
    "    text: str\n",
    "    entities: List[Entity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "test_set_path = Path(\"results.jsonl\")\n",
    "\n",
    "results = []\n",
    "\n",
    "with open(test_set_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        raw_data = json.loads(line)\n",
    "        try:\n",
    "            result = Result(**raw_data)\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing line: {e}\")\n",
    "            print(f\"Problematic data: {raw_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maish\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear University of Manitoba Development Office,\n",
      "I am delighted to be supporting your cause through a one-time gift of $20,000.\n",
      "I would like this donation to go towards the Computer Science Department's Fellowship Program. Please let me know if this is feasible and how we can make it happen. \n",
      "Thank you for your time and consideration.\n",
      "Sincerely,\n",
      "Michael Roberts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$20,000 => Money\n",
      "Computer Science Department => Faculty\n",
      "Sincerely => Address\n",
      "Michael Roberts => Person\n",
      "Dear Friends at the University of Manitoba Foundation,\n",
      "\n",
      "I am writing to express my interest in establishing a bursary for students studying Music at the university. I would like to make a one-time gift of $15,000 and a recurring gift of $1,000 every two years.\n",
      "\n",
      "Please let me know if this is feasible and what process I need to follow to set up these gifts.\n",
      "\n",
      "You can contact me at 204-456-1234 or via email at donorsmith@donorsmith.org.\n",
      "\n",
      "Thank you for your time and consideration.\n",
      "$15,000 => Money\n",
      "$1,000 => Money\n",
      "every two years => Interval\n",
      "204-456-1234 => Phone\n",
      "donorsmith@donorsmith.org => Address\n",
      "Dear University of Manitoba Development Office, I would like to set up a one-time gift to support the Civil Engineering Bursary. The amount will be $5,000 and it will be transferred via wire transfer. Could you please provide me with the necessary information on how to proceed? My contact information is 204-456-2341 and 123 Donor Lane, Toronto, ON M5J 2T3. Best regards, Dr. Sarah Thompson.\n",
      "$5,000 => Money\n",
      "204-456-2341 => Phone\n",
      "123 Donor Lane => Address\n",
      "Dr. Sarah Thompson => Person\n",
      "Dear University of Manitoba, I am writing to express my interest in setting up a one-time gift of $5,000 for the Mathematics department. This donation is meant to support the research efforts of Dr. Karen Brown. Please let me know the process to make this donation. You can reach me at 204-456-1234 or via email at contact@donorsmith.org. Thank you, Rachel Smith.\n",
      "$5,000 => Money\n",
      "Mathematics department => Faculty\n",
      "Dr. Karen Brown => Person\n",
      "204-456-1234 => Phone\n",
      "Dear University of Manitoba Development Office,\n",
      "I am writing to express my interest in making a donation to the Computer Science Department. I would like to establish a one-time gift of $5,000 for the department's use.\n",
      "\n",
      "My intention is to provide this gift as an unrestricted donation to support the department's research and teaching activities.\n",
      "\n",
      "Please let me know if there are any specific instructions or forms that I need to complete. You can reach me at 204-456-2341 or via email at contact@donorsmith.org for any further information.\n",
      "\n",
      "Thank you for your time and consideration.\n",
      "Best regards,\n",
      "Michael Roberts.\n",
      "Computer Science Department => Faculty\n",
      "$5,000 => Money\n",
      "204-456-2341 => Phone\n",
      "Michael Roberts => Person\n",
      "Dear University of Manitoba Foundation, I am excited to establish a one-time gift of $10,000 in support of the Music Department. Please let me know the best method for transferring the funds and any requirements for receipt. Thank you for your time and consideration. Best regards, Rachel Thompson.\n",
      "$10,000 => Money\n",
      "Music Department => Faculty\n",
      "Rachel Thompson => Person\n",
      "Dear University of Manitoba Development Office,\n",
      "\n",
      "I am writing to establish a one-time gift in the amount of $50,000 to support a scholarship for students pursuing a degree in Civil Engineering. The funds will be distributed annually starting from March 1, 2026.\n",
      "\n",
      "Please let me know what steps I need to take to complete this donation.\n",
      "\n",
      "You can contact me at (204) 123-4567 or via email at [donor.jones@globalgivingtrust.org](mailto:donor.jones@globalgivingtrust.org).\n",
      "\n",
      "Thank you,\n",
      "John Smith.\n",
      "$50,000 => Money\n",
      "Civil Engineering => Faculty\n",
      "annually => Interval\n",
      "March 1, 2026 => Start Date\n",
      "(204) 123-4567 => Phone\n",
      "John Smith => Person\n",
      "Dear University of Manitoba Development Office,\n",
      "I am writing to establish a bursary in the amount of $12,000 that will provide financial support to students enrolled in the Department of Mathematics. The funds will be distributed annually starting from March 2027.\n",
      "\n",
      "To facilitate this gift, please find my contact information below: Phone (204) 123-4567 and Email [jane.doe@donorlane.org](mailto:jane.doe@donorlane.org).\n",
      "Sincerely,\n",
      "Jenny Doe.\n",
      "$12,000 => Money\n",
      "Department of Mathematics => Faculty\n",
      "annually => Interval\n",
      "March 2027 => Start Date\n",
      "(204) 123-4567 => Phone\n",
      "Jenny Doe => Person\n",
      "Dear Global Giving Trust,\n",
      "Dear Global Giving Trust, I am excited to make a one-time gift of $5,000 to support the Faculty of Civil Engineering at the University of Manitoba. My intention is to establish an award for exceptional students in this field. Please let me know if this is feasible and what steps we need to take next.\n",
      "$5,000 => Money\n",
      "Faculty of Civil Engineering => Faculty\n",
      "Dear Development Office, I am pleased to make a recurring gift of $5,000 every year for five years in support of the Music Faculty scholarship fund. My intent is to provide this donation through a wire transfer from my bank account. Please let me know what information and documentation are required to complete the process. You can reach me at (204) 111-2222 or via email at contact@donorsmith.org for any questions. Thank you, John Smith.\n",
      "$5,000 => Money\n",
      "Music Faculty => Faculty\n",
      "(204) 111-2222 => Phone\n",
      "John Smith => Person\n",
      "Hello, I am pleased to donate $10,000 to the University of Manitoba's Department of Mathematics and Statistics to support a bursary. Please process my donation using a wire transfer from my bank account. I would appreciate any updates on how my gift will be utilized. Thank you for your time and efforts. Best regards, John Smith.\n",
      "$10,000 => Money\n",
      "Department of Mathematics and Statistics => Faculty\n",
      "John Smith => Person\n",
      "Dear University of Manitoba Development Office,\n",
      "I am pleased to consider making a donation of $15,000 through my company's foundation. The purpose is for the creation of an endowment fund that will support students in the Computer Science Department.\n",
      "Please let me know if this is feasible and what steps I need to take next.\n",
      "Thank you,\n",
      "Michael Roberts.\n",
      "$15,000 => Money\n",
      "Computer Science Department => Faculty\n",
      "Michael Roberts => Person\n",
      "Dear University of Manitoba Development Office, I am pleased to be able to contribute $5,000 to the Computer Science department for a one-time gift. My intention is to support the bursary program for deserving students in that faculty. Please let me know if this can be arranged and what steps I should take next. If you require any additional information, feel free to reach out at 204-111-2222 or via email at info@johndoe.com.\n",
      "$5,000 => Money\n",
      "Computer Science department => Faculty\n",
      "204-111-2222 => Phone\n",
      "info@johndoe.com => Address\n",
      "Dear University of Manitoba Foundation team, I am writing to express my intention to donate $10,000 through a wire transfer as a one-time gift for the Computer Science department's new scholarship fund. The purpose of this donation is to support a fellowship award, which will provide a student with a grant to pursue their studies in computer science. My name is Michael Roberts, and I can be reached at michael.roberts@globalgiving.org or 204-456-1234 if you have any questions. Please let me know the process for setting up this donation. Best regards, Michael Roberts.\n",
      "$10,000 => Money\n",
      "Computer Science department => Faculty\n",
      "Michael Roberts => Person\n",
      "204-456-1234 => Phone\n",
      "Michael Roberts => Person\n",
      "Dear ABC Foundation, I am pleased to inform you that my organization will be making a one-time donation of $50,000 to support the bursary program in the Faculty of Civil Engineering. This gift is part of our commitment to fostering innovation and promoting engineering excellence. Please provide instructions on how to proceed with the payment. My contact information is as follows: contact@donorsmith.org and 204-456-2341. Thank you for your time and consideration.\n",
      "$50,000 => Money\n",
      "Faculty of Civil Engineering => Faculty\n",
      "contact@donorsmith.org => Address\n",
      "204-456-2341 => Phone\n",
      "Dear Sir/Madam, I would like to donate $5,000 to the University of Manitoba's Civil Engineering department for a one-time gift. The funds will be used for bursary distribution among deserving students. Please guide me through the process and let me know what information you need from me. My payment method is wire transfer. You can reach me at 204-123-4567 or via email at [donor@example.com](mailto:donor@example.com). Thank you, John Brown.\n",
      "$5,000 => Money\n",
      "Civil Engineering department => Faculty\n",
      "204-123-4567 => Phone\n",
      "John Brown => Person\n",
      "Dear ABC Foundation team, I am pleased to offer a one-time gift of $20,000 to support the University of Manitoba's Music program. The funds will be used for bursaries to aid talented students in pursuing their musical passions. Please acknowledge receipt and let me know if there are any specific requirements for processing my donation.\n",
      "$20,000 => Money\n",
      "Music program => Faculty\n",
      "Dear University of Manitoba, I am thrilled to contribute to the future of bright students. I would like to establish a recurring gift in the amount of $5,000 per year for five years. The funds will be used to support students majoring in Mathematics and receiving a scholarship from the Department of Computer Science. You can reach me at (204) 123-4567 or through email at [info@donorjohn.com](mailto:info@donorjohn.com). Thank you, John Smith.\n",
      "$5,000 => Money\n",
      "Department of Computer Science => Faculty\n",
      "(204) 123-4567 => Phone\n",
      "John Smith => Person\n",
      "Dear ABC Foundation, I am pleased to express my interest in supporting the University of Manitoba by making a recurring gift of $5,000 per annum. This donation will be used for a bursary to assist students from underprivileged backgrounds in the Civil Engineering department. Please let me know if this is feasible and what the next steps are. You can reach me at contact@donorsmith.org or 204-456-2341. Thank you for your time and consideration. Best regards, Michael Roberts.\n",
      "$5,000 => Money\n",
      "Civil Engineering department => Faculty\n",
      "contact@donorsmith.org => Address\n",
      "204-456-2341 => Phone\n",
      "Michael Roberts => Person\n",
      "Dear University of Manitoba Development Office,\n",
      "I am pleased to make a donation in the amount of $15,000 to support the Engineering Department's research and innovation initiatives. This one-time gift will be made via wire transfer by March 1st, 2025. \n",
      "\n",
      "Please ensure that this donation is properly acknowledged and receipted. You may contact me at (204) 987-6543 or email [donor@universityofmanitoba.ca](mailto:donor@universityofmanitoba.ca) if you have any questions.\n",
      "\n",
      "Thank you for your time and consideration.\n",
      "Sincerely,\n",
      "Dr. David Taylor.\n",
      "$15,000 => Money\n",
      "Engineering Department => Faculty\n",
      "(204) 987-6543 => Phone\n",
      "donor@universityofmanitoba.ca => Address\n",
      "Dr. David Taylor => Person\n",
      "Dear University of Manitoba Development Office, I am pleased to announce that my company, Smith & Co., will be making a $10,000 donation to the Faculty of Fine Arts' scholarship program. Our contribution is in support of the 'Prairie Winds' fellowship. Please let us know the process for processing this one-time gift. You can reach me at 204-555-5678 or via email at contact@smithandco.ca. Thank you, John Smith.\n",
      "$10,000 => Money\n",
      "Faculty of Fine Arts => Faculty\n",
      "204-555-5678 => Phone\n",
      "contact@smithandco.ca => Address\n",
      "John Smith => Person\n",
      "Dear University of Manitoba Development Office, I would like to establish a fellowship in the Department of Mathematics and Statistics to support students with a focus on statistics and data science. The initial donation will be $20,000, and I am willing to make a recurring gift of $1,000 per year for 5 years. Please let me know if this is feasible and what are the next steps. You can contact me at (204) 123-4567 or via email at [jane.doe@organization.org](mailto:jane.doe@organization.org). Best regards, Jane Doe.\n",
      "Department of Mathematics and Statistics => Faculty\n",
      "$20,000 => Money\n",
      "$1,000 => Money\n",
      "(204) 123-4567 => Phone\n",
      "jane.doe => Person\n",
      "jane.doe => Person\n",
      "Jane Doe => Person\n",
      "Dear University of Manitoba Development Office,\n",
      "I am pleased to express my interest in making a donation to support the Computer Science Department's efforts. Specifically, I would like to establish a one-time gift of $10,000 for the Mathematics Faculty Scholarship. This will be funded through a wire transfer from my personal account.\n",
      "\n",
      "Please confirm receipt of this email and provide instructions on how to complete the process. You can reach me at (204) 123-4567 or via mail at 101 University Crescent, Winnipeg, MB R3T 2N9.\n",
      "\n",
      "Thank you for your time and consideration.\n",
      "Best regards,\n",
      "Michael Roberts.\n",
      "Computer Science Department => Faculty\n",
      "$10,000 => Money\n",
      "(204) 123-4567 => Phone\n",
      "101 University Crescent => Address\n",
      "Michael Roberts => Person\n",
      "Dear ABC Foundation, I am pleased to inform you that my company, Smith Inc., has decided to make a one-time gift of $50,000 in support of the bursary program at the University of Manitoba's Civil Engineering department. Please let me know the necessary details for processing this donation. You can reach me at 204-456-2341 or via email at contact@smithinc.org. Thank you for your time and consideration.\n",
      "$50,000 => Money\n",
      "Civil Engineering department => Faculty\n",
      "204-456-2341 => Phone\n",
      "contact@smithinc.org => Address\n",
      "Dear Sir/Madam,\n",
      "I would like to make a one-time gift of $50,000 to support the Music department at the University of Manitoba. This will help fund scholarships for students pursuing degrees in music.\n",
      "Could you please guide me through the process and provide any necessary forms?\n",
      "\n",
      "Thank you for your time and consideration.\n",
      "Sincerely,\n",
      "David Thompson\n",
      "$50,000 => Money\n",
      "Music department => Faculty\n",
      "Sincerely => Address\n",
      "David Thompson => Person\n",
      "Hello, I am writing to set up a bursary in the Department of Mathematics. The bursary will provide $3,000 every six months for students with a minimum GPA of 3.5. If this is feasible, please let me know and we can discuss further. You can reach me at (204) 123-4567 or via mail at 901 Manitoba Avenue, Winnipeg, MB. Thank you, Emily Lee.\n",
      "Department of Mathematics => Faculty\n",
      "$3,000 => Money\n",
      "every six months => Interval\n",
      "(204) 123-4567 => Phone\n",
      "901 Manitoba Avenue => Address\n",
      "Emily Lee => Person\n",
      "Dear Sir/Madam, I would like to make a one-time donation of $5,000 to support the bursary for students in the Computer Science Department. This will be my fifth annual gift to the University of Manitoba, and I am hoping to set up a recurring payment schedule as well. Please let me know if this is feasible and what the next steps are. You can contact me at 204-555-1234 or via email at [contact@donorsmith.org](mailto:contact@donorsmith.org). Thank you, John Smith.\n",
      "$5,000 => Money\n",
      "Computer Science Department => Faculty\n",
      "204-555-1234 => Phone\n",
      "John Smith => Person\n",
      "Dear ABC Foundation Team,\n",
      "\n",
      "I am delighted to inform you that I would like to make a recurring gift of $5,000 every year for the next five years to support the Civil Engineering department's bursary program. The first payment date will be March 1, 2026.\n",
      "\n",
      "Please let me know if this is feasible and what payment methods are available.\n",
      "\n",
      "You can reach me at (204) 456-2341 or via email at [contact@donorsmith.org](mailto:contact@donorsmith.org).\n",
      "\n",
      "Thank you for your time and consideration.\n",
      "Best regards,\n",
      "Jane Doe\n",
      "$5,000 => Money\n",
      "five years => Interval\n",
      "Civil Engineering department => Faculty\n",
      "March 1, 2026 => Start Date\n",
      "(204) 456-2341 => Phone\n",
      "Jane Doe => Person\n",
      "Dear ABC Foundation, I would like to make a one-time donation of $10,000 to the University of Manitoba's Computer Science department. My intention is to establish a bursary that will provide financial support to students. Please let me know what steps I need to take to make this donation. Thank you for your time and consideration.\n",
      "$10,000 => Money\n",
      "Computer Science department => Faculty\n",
      "Dear Sir/Madam,\n",
      "I would like to make a one-time donation of $10,000 to the Global Giving Trust for the purpose of funding research in the Faculty of Civil Engineering at the University of Manitoba. I would appreciate any information you can provide regarding your organization's procedures and any necessary documentation.\n",
      "\n",
      "Sincerely,\n",
      "Michael Roberts\n",
      "$10,000 => Money\n",
      "Faculty of Civil Engineering => Faculty\n",
      "Michael Roberts => Person\n",
      "Dear University of Manitoba Foundation,\n",
      "Dear ABC Foundation, I am pleased to donate $50,000 to the University of Manitoba's Mathematics Department as part of our company's annual giving program. This donation will go towards a bursary for undergraduate students in their second year and above. Please let me know how we can proceed with the gift. We look forward to discussing this further. Best regards, Mark Stevens.\n",
      "$50,000 => Money\n",
      "Mathematics Department => Faculty\n",
      "Mark Stevens => Person\n",
      "Dear University of Manitoba Development Office,\n",
      "I am writing to express my interest in establishing a recurring gift of $15,000 per year for five years. The purpose of this gift is to support the Civil Engineering Department's scholarship program.\n",
      "Please let me know the necessary steps to set up this donation and any tax benefits that I may be eligible for.\n",
      "Thank you,\n",
      "John Smith.\n",
      "$15,000 => Money\n",
      "Civil Engineering Department => Faculty\n",
      "John Smith => Person\n",
      "Dear Global Giving Trust,\n",
      "Dear University of Manitoba, I am pleased to make a donation of $50,000 to the Faculty of Computer Science as part of our organization's annual giving program. We believe in supporting innovation and education, particularly in the field of artificial intelligence. The payment will be made through wire transfer and is intended for a one-time gift. Please confirm receipt and let us know if there are any specific requirements or procedures we need to follow. Thank you for your time and consideration.\n",
      "$50,000 => Money\n",
      "Faculty of Computer Science => Faculty\n",
      "Dear Global Giving Trust,\n",
      "Dear University of Manitoba Development Office, I am excited to donate $10,000 to support bursaries for undergraduate students in the Faculty of Mathematics and Statistics. I would like this gift to be distributed as a one-time payment with no recurring gifts. If there are any additional requirements or paperwork needed from me, please let me know at contact@donorsmith.org.\n",
      "$10,000 => Money\n",
      "Faculty of Mathematics and Statistics => Faculty\n",
      "contact@donorsmith.org => Address\n",
      "Dear University of Manitoba Foundation,\n",
      "I am writing to express my intention to establish a one-time donation of $5,000 to support the Computer Science department. This gift will be made in honour of my mentor, Dr. John Smith.\n",
      "\n",
      "Please confirm receipt and details on how to proceed with the payment. If you need any additional information from me, please do not hesitate to contact me at (204) 123-4567 or via email at john.smith@donor.com.\n",
      "\n",
      "Thank you for your time and consideration.\n",
      "Best regards,\n",
      "Michael Roberts.\n",
      "$5,000 => Money\n",
      "Computer Science department => Faculty\n",
      "Dr. John Smith => Person\n",
      "(204) 123-4567 => Phone\n",
      "Dear University of Manitoba Development Office,\n",
      "\n",
      "I am writing to establish a one-time gift in the amount of $50,000 to support scholarships for students in the Faculty of Civil Engineering. I would like to specify that this donation should be allocated towards the John Smith Memorial Bursary.\n",
      "\n",
      "Please confirm receipt of my gift and provide information on how I can process the donation through a wire transfer or stock transfer.\n",
      "\n",
      "Thank you,\n",
      "David Chen.\n",
      "$50,000 => Money\n",
      "Faculty of Civil Engineering => Faculty\n",
      "David Chen => Person\n",
      "Dear University of Manitoba Development Office,\n",
      "I am pleased to inform you that I have decided to make a one-time gift of $5,000 to support the Civil Engineering Faculty's Bursary Program. This donation will be made through wire transfer.\n",
      "Please let me know if this can be arranged and what information is required from my end.\n",
      "\n",
      "Thank you,\n",
      "Michael Roberts.\n",
      "$5,000 => Money\n",
      "Civil Engineering Faculty => Faculty\n",
      "Michael Roberts => Person\n",
      "Dear ABC Foundation Team,\n",
      "\n",
      "I am writing to express my interest in supporting the University of Manitoba's Computer Science program through a one-time gift. I would like to donate $5,000 to fund a bursary for students who are part of the Computer Science department.\n",
      "\n",
      "Please let me know what steps I need to take to make this donation and if there are any specific requirements or guidelines that I should follow.\n",
      "\n",
      "Thank you for your time and consideration.\n",
      "\n",
      "Sincerely,\n",
      "Jane Doe\n",
      "Computer Science program => Faculty\n",
      "$5,000 => Money\n",
      "Computer Science department => Faculty\n",
      "Jane Doe => Person\n",
      "Dear University of Manitoba Development Office, I am writing to establish a one-time gift of $20,000 for the use and benefit of the Civil Engineering department. This will be paid through a wire transfer from my company's bank account. My intention is to support student research initiatives. If this is possible, please provide me with more information on how to proceed. I look forward to hearing back from you. Best regards, David Wilson.\n",
      "$20,000 => Money\n",
      "Civil Engineering department => Faculty\n",
      "David Wilson => Person\n",
      "Dear University of Manitoba Development Office,\n",
      "I am writing to make a one-time donation of $50,000 to the Civil Engineering Faculty Bursary. The funds will be used to support students pursuing their undergraduate studies in Civil Engineering.\n",
      "Please let me know how I can transfer the funds and any relevant documentation that is required.\n",
      "Thank you,\n",
      "Ruth Ann Taylor.\n",
      "$50,000 => Money\n",
      "Civil Engineering Faculty => Faculty\n",
      "Ruth Ann Taylor => Person\n",
      "Dear University of Manitoba Development Office,\n",
      "I am writing to express my interest in establishing a fellowship that supports students from the Faculty of Civil Engineering. The initial gift would be $15,000 with a goal of making quarterly payments over five years.\n",
      "Could you please guide me on how to proceed?\n",
      "\n",
      "Thank you for your time and consideration.\n",
      "Best regards,\n",
      "Michael Roberts\n",
      "Faculty of Civil Engineering => Faculty\n",
      "$15,000 => Money\n",
      "Michael Roberts => Person\n",
      "Hello, I am excited to set up a recurring donation of $500 per month to support the Engineering and Computer Science students at the University of Manitoba. Please let me know if this is feasible. If so, what are the next steps? You can contact me at jane.doe@email.com or 204-123-4567. Thank you for your time and consideration. Best regards, Jane Doe.\n",
      "$500 => Money\n",
      "Engineering and Computer Science => Faculty\n",
      "204-123-4567 => Phone\n",
      "Jane Doe => Person\n",
      "Dear University of Manitoba Development Office,\n",
      "I am writing to establish a recurring gift in the amount of $5,000 per annum for a bursary supporting students in the Computer Science department. This is a one-time payment for a pledge.\n",
      "Please process my request and confirm the details.\n",
      "Thank you,\n",
      "John Lee.\n",
      "$5,000 => Money\n",
      "Computer Science department => Faculty\n",
      "John Lee => Person\n",
      "Dear Sir/Madam,\n",
      "\n",
      "I am writing to express my interest in establishing a scholarship at the University of Manitoba. The purpose is to support a student pursuing their undergraduate studies in Civil Engineering with an award of $10,000 per year for three years. I would appreciate it if you could guide me through the process.\n",
      "\n",
      "Please feel free to contact me via email at [contact@donorsmith.org](mailto:contact@donorsmith.org) or phone at 204-456-2341.\n",
      "\n",
      "Thank you,\n",
      "Robert James.\n",
      "Civil Engineering => Faculty\n",
      "$10,000 => Money\n",
      "three years => Interval\n",
      "204-456-2341 => Phone\n",
      "Robert James => Person\n",
      "Dear Sir/Madam,\n",
      "I would like to make a one-time gift of $10,000 to support the Engineering Bursary at the University of Manitoba. Please let me know how I can proceed with this donation.\n",
      "Thank you for your time and consideration.\n",
      "Best regards,\n",
      "John Smith.\n",
      "$10,000 => Money\n",
      "John Smith => Person\n",
      "Dear ABC Foundation, I am pleased to make a one-time gift of $5,000 towards the Civil Engineering department's bursary. The funds will support students in their final year of studies. Please let me know if this can be processed promptly. You may contact me at (204) 123-4567 or via email at [donor@smith.org](mailto:donor@smith.org). Thank you, John Smith.\n",
      "$5,000 => Money\n",
      "Civil Engineering department => Faculty\n",
      "(204) 123-4567 => Phone\n",
      "John Smith => Person\n",
      "Dear Global Giving Trust, I am pleased to inform you that we are willing to contribute a total of $15,000 as a one-time gift to support the bursary for students in the Fine Arts department. Please let us know the process to proceed with this contribution.\n",
      "$15,000 => Money\n",
      "Fine Arts department => Faculty\n",
      "Dear Global Giving Trust, I am excited to make a one-time gift of $10,000 to support the Civil Engineering Department's bursary program. Please accept my donation via wire transfer to your account. Your organization has made a significant impact on the community, and I would like to contribute to this cause.\n",
      "I => Person\n",
      "$10,000 => Money\n",
      "Civil Engineering Department => Faculty\n",
      "I => Person\n",
      "Dear University of Manitoba Development Office,\n",
      "\n",
      "I am writing to establish a recurring gift of $5,000 per year for the next three years to support student bursaries in the Faculty of Civil Engineering. My intent is to make this commitment as part of our family's legacy.\n",
      "\n",
      "Please let me know what steps I need to take to formalize this gift and if there are any restrictions on how it can be used.\n",
      "\n",
      "I look forward to hearing from you soon.\n",
      "\n",
      "Best regards,\n",
      "Michael Roberts.\n",
      "$5,000 => Money\n",
      "Faculty of Civil Engineering => Faculty\n",
      "Michael Roberts => Person\n",
      "Dear University of Manitoba Development Office,\n",
      "I am writing to express my interest in establishing a recurring gift to support the Civil Engineering department's bursary program. I would like to set up a monthly payment of $500, starting from March 1, 2025.\n",
      "Please let me know if this is feasible and what steps I need to take to complete the process. You can reach me at (204) 123-4567 or via email at [donor@johnsmith.com](mailto:donor@johnsmith.com).\n",
      "Thank you for your time and consideration.\n",
      "Best regards,\n",
      "Michael Roberts\n",
      "Civil Engineering department => Faculty\n",
      "$500 => Money\n",
      "March 1, 2025 => Start Date\n",
      "(204) 123-4567 => Phone\n",
      "Michael Roberts => Person\n",
      "Dear Sir/Madam,\n",
      "\n",
      "I am writing to express my interest in setting up a one-time gift of $20,000 for the Computer Science department. This donation will be used towards supporting the faculty's research initiatives.\n",
      "\n",
      "If possible, could you please let me know what information I would need to provide and how to proceed with the payment?\n",
      "\n",
      "You can contact me at (204) 123-4567 or email me at [donor@smith.com](mailto:donor@smith.com).\n",
      "\n",
      "Thank you for your time and consideration.\n",
      "\n",
      "Best regards,\n",
      "John Smith.\n",
      "$20,000 => Money\n",
      "(204) 123-4567 => Phone\n",
      "John Smith => Person\n",
      "Dear University of Manitoba Development Office, I am pleased to support the Computer Science department at your institution with a one-time gift of $5,000. This donation will be used for research and education purposes. Please let me know if there are any specific requirements or processes you need from me to finalize this donation. Thank you for your time and consideration. Best regards, Dr. Rachel Lee.\n",
      "Computer Science department => Faculty\n",
      "$5,000 => Money\n",
      "Dr. Rachel Lee => Person\n",
      "Dear University of Manitoba Development Office, I am pleased to inform you that the ABC Foundation is establishing a recurring gift in the amount of $50,000 per year. The initial payment will be made on March 1st, 2025, and subsequent payments will be made annually thereafter. Our intention is to support a bursary for students studying in the Faculty of Civil Engineering. Please let us know if this is feasible.\n",
      "$50,000 => Money\n",
      "March 1st, 2025 => Start Date\n",
      "Faculty of Civil Engineering => Faculty\n",
      "Hello University of Manitoba Foundation, I am pleased to inform you that we have decided to make a one-time gift of $10,000 for the Department of Music's music bursary program. We would like to contribute this amount to support students pursuing higher education in this field. Please let us know if this is possible and what steps we need to take to process this payment.\n",
      "$10,000 => Money\n",
      "Department of Music => Faculty\n",
      "Hello, I am pleased to donate a one-time gift of $10,000 to support the University of Manitoba's Computer Science Department. Please let me know if this can be directed towards a specific award or prize. You may reach me at (204) 123-4567 or via email at [donor@universityofmanitoba.ca](mailto:donor@universityofmanitoba.ca). Best regards, Rachel Brown.\n",
      "$10,000 => Money\n",
      "Computer Science Department => Faculty\n",
      "(204) 123-4567 => Phone\n",
      "Rachel Brown => Person\n",
      "Hello, I am pleased to inform you that our company is making a one-time gift of $20,000 to the University's Computer Science department. This donation will support research initiatives in this area. We would like to request information on how to facilitate the transfer. Thank you for your time and consideration. Please feel free to contact me at 204-456-1234 or at our address: 1011 Wellington Avenue, Winnipeg, MB.\n",
      "$20,000 => Money\n",
      "Computer Science department => Faculty\n",
      "204-456-1234 => Phone\n",
      "1011 Wellington Avenue => Address\n",
      "Dear University of Manitoba, I would like to establish a one-time gift of $15,000 to support students in the Department of Mathematics. The funds will be used for bursaries and scholarships. I am interested in making this donation as a stock transfer. Please let me know if this is possible and what information you require from me.\n",
      "I => Person\n",
      "$15,000 => Money\n",
      "Department of Mathematics => Faculty\n",
      "I => Person\n",
      "Dear ABC Foundation team, I am excited to make a donation of $10,000 to support the Civil Engineering Department's bursary program. I would like to set up a recurring gift of $1,000 per month for the next 12 months. Please let me know if this is feasible and what steps I need to take. You can contact me at johndoe@email.com or (204) 456-7890. Thank you for your time.\n",
      "$10,000 => Money\n",
      "Civil Engineering Department => Faculty\n",
      "$1,000 => Money\n",
      "(204) 456-7890 => Phone\n",
      "Dear University of Manitoba Development Office, I am pleased to inform you that our company is planning a recurring gift in the amount of $5,000 per month for 24 months starting from January 1, 2026. The purpose of this gift is to support the university's music department and we would like to know if there are any specific instructions or guidelines we should follow. You can reach us at contact@donorsmith.org or by phone at 204-456-2341 for more information. Thank you for your time and consideration. Best regards, Michael Roberts.\n",
      "$5,000 => Money\n",
      "24 months => Interval\n",
      "January 1, 2026 => Start Date\n",
      "music department => Faculty\n",
      "contact@donorsmith.org => Address\n",
      "204-456-2341 => Phone\n",
      "Michael Roberts => Person\n",
      "Dear Global Giving Trust, I am pleased to support the Civil Engineering department at the University of Manitoba with a one-time gift of $10,000. This donation will be used for the establishment of an annual bursary award. Please let me know the process and deadline for this gift. You can reach me at contact@donorsmith.org or 204-456-2341. Best regards, Michael Roberts.\n",
      "Civil Engineering department => Faculty\n",
      "$10,000 => Money\n",
      "contact@donorsmith.org => Address\n",
      "204-456-2341 => Phone\n",
      "Michael Roberts => Person\n",
      "Dear University of Manitoba Foundation, I am pleased to make a one-time donation of $10,000 to support the development of a new engineering facility at the Civil Engineering department. The funds will be used towards a scholarship for outstanding students in their final year. Please provide instructions on how to complete this gift and acknowledge my contribution.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(text)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Use the correct API for text input - GLiNER expects text directly\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m entities = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_entities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Display predicted entities and their labels\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m entity \u001b[38;5;129;01min\u001b[39;00m entities:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\gliner\\model.py:242\u001b[39m, in \u001b[36mGLiNER.predict_entities\u001b[39m\u001b[34m(self, text, labels, flat_ner, threshold, multi_label)\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_entities\u001b[39m(\n\u001b[32m    227\u001b[39m     \u001b[38;5;28mself\u001b[39m, text, labels, flat_ner=\u001b[38;5;28;01mTrue\u001b[39;00m, threshold=\u001b[32m0.5\u001b[39m, multi_label=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    228\u001b[39m ):\n\u001b[32m    229\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    230\u001b[39m \u001b[33;03m    Predict entities for a single text input.\u001b[39;00m\n\u001b[32m    231\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    240\u001b[39m \u001b[33;03m        The list of entity predictions.\u001b[39;00m\n\u001b[32m    241\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_predict_entities\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mflat_ner\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflat_ner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmulti_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmulti_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\gliner\\model.py:270\u001b[39m, in \u001b[36mGLiNER.batch_predict_entities\u001b[39m\u001b[34m(self, texts, labels, flat_ner, threshold, multi_label)\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    255\u001b[39m \u001b[33;03mPredict entities for a batch of texts.\u001b[39;00m\n\u001b[32m    256\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    265\u001b[39m \u001b[33;03m    The list of lists with predicted entities.\u001b[39;00m\n\u001b[32m    266\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    268\u001b[39m model_input, raw_batch = \u001b[38;5;28mself\u001b[39m.prepare_model_inputs(texts, labels)\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m model_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model_output, torch.Tensor):\n\u001b[32m    273\u001b[39m     model_output = torch.from_numpy(model_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\gliner\\modeling\\base.py:233\u001b[39m, in \u001b[36mSpanModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, labels_embeddings, labels_input_ids, labels_attention_mask, words_embedding, mask, prompts_embedding, prompts_embedding_mask, words_mask, text_lengths, span_idx, span_mask, labels, **kwargs)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,        \n\u001b[32m    216\u001b[39m             input_ids: Optional[torch.FloatTensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    217\u001b[39m             attention_mask: Optional[torch.LongTensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    230\u001b[39m             **kwargs\n\u001b[32m    231\u001b[39m             ):\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m     prompts_embedding, prompts_embedding_mask, words_embedding, mask = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_representations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m                                                                            \u001b[49m\u001b[43mlabels_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m                                                                                                                \u001b[49m\u001b[43mtext_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwords_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m     span_idx = span_idx*span_mask.unsqueeze(-\u001b[32m1\u001b[39m)\n\u001b[32m    238\u001b[39m     span_rep = \u001b[38;5;28mself\u001b[39m.span_rep_layer(words_embedding, span_idx)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\gliner\\modeling\\base.py:182\u001b[39m, in \u001b[36mBaseModel.get_representations\u001b[39m\u001b[34m(self, input_ids, attention_mask, labels_embeddings, labels_input_ids, labels_attention_mask, text_lengths, words_mask, **kwargs)\u001b[39m\n\u001b[32m    177\u001b[39m     prompts_embedding, prompts_embedding_mask, words_embedding, mask = \u001b[38;5;28mself\u001b[39m.get_bi_representations(\n\u001b[32m    178\u001b[39m             input_ids, attention_mask, labels_embeddings, labels_input_ids, labels_attention_mask, \n\u001b[32m    179\u001b[39m                                                                 text_lengths, words_mask, **kwargs\n\u001b[32m    180\u001b[39m     )\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     prompts_embedding, prompts_embedding_mask, words_embedding, mask = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_uni_representations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m                            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwords_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prompts_embedding, prompts_embedding_mask, words_embedding, mask\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\gliner\\modeling\\base.py:126\u001b[39m, in \u001b[36mBaseModel.get_uni_representations\u001b[39m\u001b[34m(self, input_ids, attention_mask, text_lengths, words_mask, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_uni_representations\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[32m    120\u001b[39m             input_ids: Optional[torch.FloatTensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    121\u001b[39m             attention_mask: Optional[torch.LongTensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    122\u001b[39m             text_lengths: Optional[torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    123\u001b[39m             words_mask: Optional[torch.LongTensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    124\u001b[39m             **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     token_embeds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtoken_rep_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m     prompts_embedding, prompts_embedding_mask, words_embedding, mask = \u001b[38;5;28mself\u001b[39m._extract_prompt_features_and_word_embeddings(token_embeds, input_ids, attention_mask, \n\u001b[32m    129\u001b[39m                                                                                                     text_lengths, words_mask)\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.has_rnn:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\gliner\\modeling\\encoder.py:136\u001b[39m, in \u001b[36mEncoder.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     token_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m token_embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\gliner\\modeling\\encoder.py:130\u001b[39m, in \u001b[36mEncoder.encode_text\u001b[39m\u001b[34m(self, input_ids, attention_mask, *args, **kwargs)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     token_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbert_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mprojection\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    132\u001b[39m         token_embeddings = \u001b[38;5;28mself\u001b[39m.projection(token_embeddings)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\gliner\\modeling\\encoder.py:100\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     99\u001b[39m     output_hidden_states = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.fuse_layers:\n\u001b[32m    103\u001b[39m     encoder_layer = \u001b[38;5;28mself\u001b[39m.layers_fuser(output.hidden_states)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:870\u001b[39m, in \u001b[36mDebertaV2Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    860\u001b[39m     token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n\u001b[32m    862\u001b[39m embedding_output = \u001b[38;5;28mself\u001b[39m.embeddings(\n\u001b[32m    863\u001b[39m     input_ids=input_ids,\n\u001b[32m    864\u001b[39m     token_type_ids=token_type_ids,\n\u001b[32m   (...)\u001b[39m\u001b[32m    867\u001b[39m     inputs_embeds=inputs_embeds,\n\u001b[32m    868\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m870\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    877\u001b[39m encoded_layers = encoder_outputs[\u001b[32m1\u001b[39m]\n\u001b[32m    879\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.z_steps > \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:674\u001b[39m, in \u001b[36mDebertaV2Encoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[39m\n\u001b[32m    664\u001b[39m     output_states, attn_weights = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    665\u001b[39m         layer_module.\u001b[34m__call__\u001b[39m,\n\u001b[32m    666\u001b[39m         next_kv,\n\u001b[32m   (...)\u001b[39m\u001b[32m    671\u001b[39m         output_attentions,\n\u001b[32m    672\u001b[39m     )\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m674\u001b[39m     output_states, attn_weights = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnext_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[32m    684\u001b[39m     all_attentions = all_attentions + (attn_weights,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:442\u001b[39m, in \u001b[36mDebertaV2Layer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[39m\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    434\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    435\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    440\u001b[39m     output_attentions: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    441\u001b[39m ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m     attention_output, att_matrix = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    450\u001b[39m     intermediate_output = \u001b[38;5;28mself\u001b[39m.intermediate(attention_output)\n\u001b[32m    451\u001b[39m     layer_output = \u001b[38;5;28mself\u001b[39m.output(intermediate_output, attention_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:375\u001b[39m, in \u001b[36mDebertaV2Attention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    367\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    368\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    373\u001b[39m     rel_embeddings=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    374\u001b[39m ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     self_output, att_matrix = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    383\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m query_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m         query_states = hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:255\u001b[39m, in \u001b[36mDisentangledSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.relative_attention:\n\u001b[32m    254\u001b[39m     rel_embeddings = \u001b[38;5;28mself\u001b[39m.pos_dropout(rel_embeddings)\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m     rel_att = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdisentangled_attention_bias\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factor\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rel_att \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    260\u001b[39m     attention_scores = attention_scores + rel_att\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:310\u001b[39m, in \u001b[36mDisentangledSelfAttention.disentangled_attention_bias\u001b[39m\u001b[34m(self, query_layer, key_layer, relative_pos, rel_embeddings, scale_factor)\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.share_att_key:\n\u001b[32m    307\u001b[39m     pos_query_layer = \u001b[38;5;28mself\u001b[39m.transpose_for_scores(\n\u001b[32m    308\u001b[39m         \u001b[38;5;28mself\u001b[39m.query_proj(rel_embeddings), \u001b[38;5;28mself\u001b[39m.num_attention_heads\n\u001b[32m    309\u001b[39m     ).repeat(query_layer.size(\u001b[32m0\u001b[39m) // \u001b[38;5;28mself\u001b[39m.num_attention_heads, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     pos_key_layer = \u001b[38;5;28mself\u001b[39m.transpose_for_scores(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m.num_attention_heads).repeat(\n\u001b[32m    311\u001b[39m         query_layer.size(\u001b[32m0\u001b[39m) // \u001b[38;5;28mself\u001b[39m.num_attention_heads, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m\n\u001b[32m    312\u001b[39m     )\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    314\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mc2p\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pos_att_type:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from gliner import GLiNER\n",
    "\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_large-v2.1\", local_files_only= True)\n",
    "\n",
    "labels = [\"Interval\", \"Money\", \"Start Date\", \"Phone\", \"Address\", \"Person\", \"Faculty\"]\n",
    "\n",
    "for result in results:\n",
    "    text = result.text\n",
    "    print(text)\n",
    "    # Use the correct API for text input - GLiNER expects text directly\n",
    "    entities = model.predict_entities(text, labels, threshold=0.8)\n",
    "\n",
    "    # Display predicted entities and their labels\n",
    "    for entity in entities:\n",
    "        print(entity[\"text\"], \"=>\", entity[\"label\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
